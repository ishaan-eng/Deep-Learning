{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kFZRpLpK02pB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Name and PRN:\n",
    "- Name: ______________________\n",
    "- PRN : ______________________\n",
    "- Date: ______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deSnZmVy02pF",
    "tags": []
   },
   "source": [
    "# Image Processing with Neural Network\n",
    "\n",
    "## Assignment: A04\n",
    "### Take Neural Network with :\n",
    "- Multiple hidden layers \n",
    "- Activation function of your choice\n",
    "\n",
    "\n",
    "### Assignment\n",
    "- **Q1**: Is this model more accurate compared to previous model?\n",
    "- **Q2**: Prepare table by changing number of neurons in hidden layer, learning rate and observe change in results. Also comment on your results.\n",
    "\n",
    "|#|Dimension of hidden layer|Learning rate|Training Accuracy|Test Accuracy|Comment|\n",
    "|:-:|:-:|:-:|:-:|:-:|:--|\n",
    "|1|5-5-4-3-2|0.1|0.97|0.96|Base case||1|4|0.1|0.97|0.96|Base case|\n",
    "|2|10-5-4-3-2|1|???|???|???|\n",
    "|...|...|...|...|...|...|\n",
    "|n|...|...|...|...|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-----------------\n",
    "### Import libraries\n",
    "###-----------------\n",
    "from pathlib import Path  # Import Path for file system path operations and management\n",
    "import numpy as np  # Import NumPy for numerical computations and array operations\n",
    "import pandas as pd  # Import Pandas for data manipulation and analysis with DataFrames\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for creating static, interactive visualizations\n",
    "import seaborn as sns  # Import Seaborn for statistical data visualization built on Matplotlib\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "from sklearn.model_selection import train_test_split  # Import function to split dataset into training and testing subsets\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             confusion_matrix,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             f1_score)  # Import function to calculate various metric\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Global Parameters ---\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "rng = np.random.default_rng(seed=RANDOM_STATE)\n",
    "TEST_SIZE  = 0.2\n",
    "NOISE=0.2\n",
    "EPOCHS=10000 # Reduced epochs for faster execution, results in table are based on this.\n",
    "N_SAMPLE=1000\n",
    "ALPHA=0.01 # Default Alpha\n",
    "\n",
    "CMAP = plt.cm.coolwarm\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fn_plot_decision_boundary(X: np.ndarray, y: np.ndarray, model:dict, predict):\n",
    "    \"\"\"\n",
    "    Plots the decision boundary for a classification model along with the data points.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Input feature matrix with shape (n_samples, 3)\n",
    "        wts (np.ndarray): Weights matrix\n",
    "        pred_function: Function to predict using weights and datapoints\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the figure with specified dimensions\n",
    "    fig, ax = plt.subplots( figsize=(8, 5) )\n",
    "\n",
    "    # Small increment value to create a fine grid for smooth decision boundary\n",
    "    dm = 0.05\n",
    "    padding = 2 * dm\n",
    "\n",
    "    # Calculate the range for x-axis (first feature) with padding\n",
    "    x_min, x_max = X[:, 0].min() - padding, X[:, 0].max() + padding\n",
    "\n",
    "    # Calculate the range for y-axis (second feature) with padding\n",
    "    y_min, y_max = X[:, 1].min() - padding, X[:, 1].max() + padding\n",
    "\n",
    "    # Create a mesh grid covering the entire feature space\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, dm),\n",
    "                         np.arange(y_min, y_max, dm))\n",
    "\n",
    "    # Flatten the mesh grid arrays and stack them column-wise to create coordinate pairs\n",
    "    XX = np.c_[xx.ravel(), yy.ravel()] # Resulting shape: (n_points, 2)\n",
    "\n",
    "    # # Add a column of ones to the coordinate array for the bias term\n",
    "    # XX = np.hstack((XX, np.ones((XX.shape[0], 1)))) # make array compatible\n",
    "\n",
    "    # List to collect predictions for each point in the mesh grid\n",
    "    y_pred = predict(model, XX)\n",
    "\n",
    "    # Iterate over each coordinate point in the mesh grid\n",
    "    # for row in XX:\n",
    "    #     # Make prediction for the current coordinate using global 'weights' and 'predict' function\n",
    "    #     y_p = predict(model, X)\n",
    "    #     y_pred.append(y_p)\n",
    "\n",
    "\n",
    "    # Reshape predictions to match the original mesh grid dimensions\n",
    "    Z = np.array(y_pred).reshape(xx.shape)\n",
    "\n",
    "    # Create filled contour plot showing the decision regions\n",
    "    ax.contourf(xx, yy, Z, alpha=0.6, cmap='rainbow')\n",
    "\n",
    "    # Scatter plot of the actual data points, colored by their true class labels\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k', cmap='rainbow')\n",
    "\n",
    "    # Set plot title and axis labels\n",
    "    ax.set_title('Decision Boundary')\n",
    "    ax.set_xlabel('A')\n",
    "    ax.set_ylabel('B')\n",
    "\n",
    "    # Display the final plot\n",
    "    plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X,y=make_moons(n_samples=N_SAMPLE,noise=NOISE,random_state=RANDOM_STATE,shuffle=True)\n",
    "type(X),type(y)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss=StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fn_softmax(z):\n",
    "    exp_score = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_score / np.sum(exp_score, axis=1, keepdims=True)\n",
    "\n",
    "def fn_activ(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def fn_activ_prime(z):\n",
    "    return 1.0 - np.tanh(z)**2\n",
    "\n",
    "def calculate_a(X_p, model):\n",
    "    W1, W2, W3, W4, W5 = model['W1'], model['W2'], model['W3'], model['W4'], model['W5']\n",
    "    b1, b2, b3, b4, b5 = model['b1'], model['b2'], model['b3'], model['b4'], model['b5']\n",
    "\n",
    "    # Forward Propagation\n",
    "    z1 = X_p.dot(W1) + b1\n",
    "    a1 = fn_activ(z1)\n",
    "\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    a2 = fn_activ(z2)\n",
    "\n",
    "    z3 = a2.dot(W3) + b3\n",
    "    a3 = fn_activ(z3)\n",
    "\n",
    "    z4 = a3.dot(W4) + b4\n",
    "    a4 = fn_activ(z4)\n",
    "\n",
    "    z5 = a4.dot(W5) + b5\n",
    "    a5 = fn_softmax(z5)\n",
    "    return a5, a4, a3, a2, a1, z5, z4, z3, z2, z1\n",
    "\n",
    "def predict(model, X_p):\n",
    "    a5, _, _, _, _, _, _, _, _, _ = calculate_a(X_p, model)\n",
    "    return a5.argmax(axis=1)\n",
    "\n",
    "def build_model_and_train(h_dim_config, X_tr, y_tr, X_ts, y_ts, alpha, n_epochs, random_state=42):\n",
    "    # Setup for 4 hidden layers\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "    h_dim = [X_tr.shape[1]] + h_dim_config + [y_tr.shape[1]]\n",
    "\n",
    "    W1 = rng.random((h_dim[0], h_dim[1])) / np.sqrt(h_dim[0])\n",
    "    W2 = rng.random((h_dim[1], h_dim[2])) / np.sqrt(h_dim[1])\n",
    "    W3 = rng.random((h_dim[2], h_dim[3])) / np.sqrt(h_dim[2])\n",
    "    W4 = rng.random((h_dim[3], h_dim[4])) / np.sqrt(h_dim[3])\n",
    "    W5 = rng.random((h_dim[4], h_dim[5])) / np.sqrt(h_dim[4])\n",
    "\n",
    "    b1, b2, b3, b4, b5 = [np.zeros((1, d)) for d in h_dim[1:]]\n",
    "    m = X_tr.shape[0]\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        model = {'W1': W1, 'W2': W2, 'W3': W3, 'W4': W4, 'W5': W5,\n",
    "                 'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5': b5}\n",
    "\n",
    "        a5, a4, a3, a2, a1, z5, z4, z3, z2, z1 = calculate_a(X_tr, model)\n",
    "\n",
    "        # Back Propagation\n",
    "        dz5, dw5, db5, da4 = [a5 - y_tr, (a4.T).dot(dz5), np.sum(dz5, axis=0, keepdims=True), dz5.dot(W5.T)]\n",
    "        dz4, dw4, db4, da3 = [da4 * fn_activ_prime(z4), (a3.T).dot(dz4), np.sum(dz4, axis=0, keepdims=True), dz4.dot(W4.T)]\n",
    "        dz3, dw3, db3, da2 = [da3 * fn_activ_prime(z3), (a2.T).dot(dz3), np.sum(dz3, axis=0, keepdims=True), dz3.dot(W3.T)]\n",
    "        dz2, dw2, db2, da1 = [da2 * fn_activ_prime(z2), (a1.T).dot(dz2), np.sum(dz2, axis=0, keepdims=True), dz2.dot(W2.T)]\n",
    "        dz1, dw1, db1 = [da1 * fn_activ_prime(z1), (X_tr.T).dot(dz1), np.sum(dz1, axis=0, keepdims=True)]\n",
    "\n",
    "        # Parameter Update\n",
    "        W1 -= alpha * dw1 / m; b1 -= alpha * db1 / m\n",
    "        W2 -= alpha * dw2 / m; b2 -= alpha * db2 / m\n",
    "        W3 -= alpha * dw3 / m; b3 -= alpha * db3 / m\n",
    "        W4 -= alpha * dw4 / m; b4 -= alpha * db4 / m\n",
    "        W5 -= alpha * dw5 / m; b5 -= alpha * db5 / m\n",
    "\n",
    "    final_model = {'W1': W1, 'W2': W2, 'W3': W3, 'W4': W4, 'W5': W5,\n",
    "                   'b1': b1, 'b2': b2, 'b3': b3, 'b4': b4, 'b5': b5}\n",
    "\n",
    "    # Evaluate\n",
    "    y_tr_pred = predict(final_model, X_tr)\n",
    "    y_ts_pred = predict(final_model, X_ts)\n",
    "\n",
    "    tr_acc = accuracy_score(y_tr.argmax(axis=1), y_tr_pred)\n",
    "    ts_acc = accuracy_score(y_ts.argmax(axis=1), y_ts_pred)\n",
    "\n",
    "    return tr_acc, ts_acc"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "experiments = [\n",
    "    {\"id\": 1, \"h_dim_config\": [5, 5, 4, 3], \"alpha\": 0.1},\n",
    "    {\"id\": 2, \"h_dim_config\": [10, 5, 4, 3], \"alpha\": 1.0},\n",
    "    {\"id\": 3, \"h_dim_config\": [50, 20, 10, 5], \"alpha\": 0.05},\n",
    "    {\"id\": 4, \"h_dim_config\": [100, 100, 100, 100], \"alpha\": 0.001}\n",
    "]\n",
    "\n",
    "results = []\n",
    "# Run each experiment and append to results list\n",
    "for exp in experiments:\n",
    "    tr_acc, ts_acc = build_model_and_train(\n",
    "        h_dim_config=exp['h_dim_config'],\n",
    "        X_tr=X_train,\n",
    "        y_tr=y_train,\n",
    "        X_ts=X_test,\n",
    "        y_ts=y_test,\n",
    "        alpha=exp['alpha'],\n",
    "        n_epochs=EPOCHS\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "S05a_one_hidden_layer_with_tanh_wip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
